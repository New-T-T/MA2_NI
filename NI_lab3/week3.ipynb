{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: simulate a Winner-Take-All (WTA) network using DYNAP-SE1 models\n",
    "\n",
    "By [Jingyue Zhao](https://www.ini.uzh.ch/fw1/modules/ini/ini.php/people/jzhao), [Elisa Donati](https://www.ini.uzh.ch/fw1/modules/ini/ini.php/people/elisa) and \n",
    "[Giacomo Indiveri](https://www.ini.uzh.ch/fw1/modules/ini/ini.php/people/giacomo) \n",
    "\n",
    "In this exercise we will simulate a Winner-Take-All (WTA) network using DYNAP-SE1 neuron and synapse models. Specifically, we will create a population of neurons connected with local excitation and global inhibition to form a population code. In practice, we often use WTA as one the building blocks of our SNN models. Therefore this exercise of a simulated WTA can be later transformed to a hardware version on DYNAP-SE1.\n",
    "\n",
    "In this tutorial, we will use 32 excitatory neurons (i.e., the excitatory population) and 8 inhibitory neurons (i.e., the inhibitory population) to create a Winner-Take-All network. As shown in the figure below, local excitation and global inhibition are constructed in a WTA network. \n",
    "\n",
    "<center><img src=\"img/wta.png\" alt=\"WTA circuit.\" style=\"width: 700px;\"></center>\n",
    "\n",
    "* Local excitation\n",
    "    * Feedforward excitatory-inhibition (EI) connections: each excitatory neuron activates the inhibitory neurons with probabilistic connections.\n",
    "    * Recurrent excitatory-excitatory (EE) connections: each excitatory neuron sends connections to itself (self-excitation) and/or to its neighbors (lateral excitation). Usually, the weights of the recurrent connections are non-decreasing in a sense that neurons that are closer to each other are more correleted.\n",
    "\n",
    "- Global inhibition\n",
    "    * Inhibitory-excitatory (IE) connections: each inhibitory neuron is randomly connected to all the excitatory neurons with a certain connection probability.\n",
    "\n",
    "\n",
    "Thanks to the wonderful dynamics of WTA, it presents some good features, e.g. encoding a variable/state robustly using space coding, signal restoration, cue integration, etc. You can see these functions in Figure 2 of this [paper](https://arxiv.org/abs/1608.08267))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first import all the required Python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brian2 import *\n",
    "from DynapSE import DynapSE\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display plots inside Jupyter cell\n",
    "%matplotlib inline \n",
    "# Set the dots-per-inch (resolution) of the images\n",
    "mpl.rcParams['figure.dpi'] = 90\n",
    "\n",
    "from equations.dynapse_eq import *\n",
    "from parameters.dynapse_param import *\n",
    "\n",
    "# C++ code generation for faster spiking network simulation\n",
    "set_device('cpp_standalone')\n",
    "# Ignore Brian2 base warnings\n",
    "BrianLogger.suppress_name('base')\n",
    "# The clock of Brian2 simulation for numerically solve ODEs\n",
    "defaultclock.dt = 20 * us"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create neuron populations\n",
    "We will create one excitatory population with 32 neurons, and one inhibitory neurons with 8 neurons, following the ratio between excitatory neurons and inhibitory neurons in biology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to start a new build to run multiple full simulations\n",
    "device.reinit()\n",
    "device.activate()\n",
    "# need to reset the defaultclock after activate\n",
    "defaultclock.dt = 20 * us\n",
    "\n",
    "# create a network\n",
    "network = Network()\n",
    "chip = DynapSE(network)\n",
    "\n",
    "# define the network parameters\n",
    "# number of exc neurons\n",
    "num_exc = 32\n",
    "# number of inh neurons\n",
    "num_inh = 8\n",
    "\n",
    "######################## TODO ########################\n",
    "\n",
    "# create exc population\n",
    "\n",
    "# create inh population\n",
    "\n",
    "######################## TODO ########################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create spike generators\n",
    "\n",
    "We then define a group of Poisson spike generators to stimulate the excitatory neurons with one-to-one connections. Here we create 2 bumps of firing rates in the shape of a Gaussian distribution. The first 16 spike generators form a higher peak with 120 Hz in the Gaussian center, while the second half of them form a lower bump with the maximum firing rate at 80 Hz, which mimics the rate distribution of the \"Input Stimulus\" in page 28 of the lecture slides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poisson rate of each spike generator\n",
    "# which forms a population code with a bump\n",
    "\n",
    "# define the shape of the Gaussian bump\n",
    "value=0.5\n",
    "sigma=10\n",
    "amplitude=200\n",
    "\n",
    "def gaussian(x, mu, sigma = 1.0):\n",
    "    '''\n",
    "    Author: Jingyue\n",
    "    Calculate the Gaussian value given a position x, the Guassian center mu and sigma.\n",
    "    '''\n",
    "    return np.exp(-np.power(x - mu, 2.) / (2 * np.power(sigma, 2.)))\n",
    "\n",
    "def double2pop_code(value, inputSize=16, sigma=1, amplitude=100):\n",
    "    '''\n",
    "    Author: Jingyue\n",
    "    Convert a normalized value in [0,1] to a population code represented by\n",
    "    a group of neurons. \n",
    "    value: normalized value\n",
    "    inputSize: size of the neuron population\n",
    "    sigma: Gaussian sigma\n",
    "    amplitude: firing rate of the Gaussian center\n",
    "    \n",
    "    return:\n",
    "        rates: array of firing rates encoding a normalized variable\n",
    "    '''\n",
    "    rates = []\n",
    "    mu = value*(inputSize - 1)\n",
    "    \n",
    "    for i in range(inputSize):\n",
    "        rate = amplitude * gaussian(float(i), float(mu), float(sigma))\n",
    "        rates.append(rate)\n",
    "        \n",
    "    return rates\n",
    "\n",
    "rates_bump_1 = double2pop_code(value=0.5, inputSize=int(num_exc/2), sigma=3, amplitude=120)\n",
    "\n",
    "rates_bump_2 = double2pop_code(value=0.5, inputSize=int(num_exc/2), sigma=3, amplitude=80)\n",
    "\n",
    "rates = rates_bump_1 + rates_bump_2\n",
    "\n",
    "# create spike generators for each exc neuron\n",
    "spikegen = PoissonGroup(num_exc, rates*Hz)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the mean firing rates of the Poisson spike generators to visualize the 2 bumps. We will see how the WTA network handle these 2 bumps later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(num_exc), rates, '.-')\n",
    "plt.title('Mean Firing Rates of the Input Stimulus')\n",
    "plt.xlabel('Neuron address')    \n",
    "plt.ylabel('Mean firing rate (Hz)')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create connections\n",
    "Following the description of the WTA network mentioned above, we will create 4 types of synapses between different neuron groups.\n",
    "* syn_inp: one-to-one connections from Poisson spike generators to the excitatory neurons\n",
    "* syn_ee: recurrent excitatory connections inside the excitatory population\n",
    "* syn_ei: random all-to-all connections from the excitatory population to the inhibitory population with probability = p_ei\n",
    "* syn_ie: random all-to-all connections from the inhibitory population to the excitatory population with probability = p_ie\n",
    "\n",
    "For `syn_ee`, we use a Gaussian kernel to model the distance-dreasing weights of the recurrent connections. Let's first take a look at the connection pattern generation. The two arrays `output_i` and `output_j` can be used to create the synapses, e.g. `synapse.connect(i=output_i, j=output_j)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_recurrent_excitation(size, baseWeight, sigma=3.0, self_exc=True):\n",
    "    '''\n",
    "    Author: Jingyue\n",
    "    For a pre neuron, use its neuron id as the mean of Gaussian, calculate the value at\n",
    "    every other neuron id which is the weight of the synapse.\n",
    "    \n",
    "    size: number of neurons\n",
    "    baseWeight: maximum weight at the center\n",
    "    sigma: Gaussian parameter\n",
    "    self_exc: if you want to have self-excitation or not\n",
    "    \n",
    "    return:\n",
    "        output_i: pre neuron ids\n",
    "        output_j: post neuron ids\n",
    "    '''\n",
    "    output_i = []\n",
    "    output_j = []\n",
    "    floatWeightMr = np.zeros((size,size))\n",
    "    \n",
    "    for pre in range(size):\n",
    "        mu = pre\n",
    "        for post in range(size):\n",
    "            if pre == post and self_exc == False:\n",
    "                continue\n",
    "            else:\n",
    "                # for each neuron id, calculate the synapse weight at every other neurons\n",
    "                weight = int(baseWeight * gaussian(float(post), float(mu), float(sigma)) )\n",
    "                floatWeightMr[pre][post] = weight\n",
    "\n",
    "                # add weight connections between pre and post\n",
    "                for k in range(weight):\n",
    "                    output_i.append(pre)\n",
    "                    output_j.append(post)\n",
    "            \n",
    "    print(floatWeightMr[16])\n",
    "        \n",
    "    return output_i, output_j  \n",
    "\n",
    "output_i, output_j = gaussian_recurrent_excitation(32, 1, 1, True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print the weight matrix of neuron 16 in this function. And you can see that with `baseWeight=1, sigma=1, self_exc=True`, neuron 16 only sends 1 connection to itself. \n",
    "\n",
    "Let's now create the whole network connections. Here, we first turn off the WTA recurrent and feedback connections to observe the behavior of a pure feedforward network. We only set the weight of syn_inp to be positive, and all the other synaptic weights to be zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define connection pattern parameters\n",
    "# probability of EI connections\n",
    "p_ei = 0.8\n",
    "# probability of IE connections\n",
    "p_ie = 0.8\n",
    "\n",
    "############################## TODO ##############################\n",
    "\n",
    "# syn_inp, spikegen to exc, one to one, NMDA\n",
    "\n",
    "# syn_ee, EE: use gaussian_recurrent_excitation(), NMDA\n",
    "\n",
    "# syn_ei, EI: all to all with probability = 0.8, AMPA\n",
    "\n",
    "# syn_ie, IE: all to all with probability = 0.8, GABA_B\n",
    "\n",
    "############################## TODO ##############################\n",
    "\n",
    "# set weights\n",
    "syn_inp.weight = 300\n",
    "syn_ee.weight = 0\n",
    "syn_ei.weight = 0\n",
    "syn_ie.weight = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create monitors and run the simulation\n",
    "Let's create some spike monitors to observe the input and output firing rates of the spike generators and excitatory neuron group. Then add all the network components into a Brian2 network, and run the simulation. The synaptic parameters are tuned and given here to reproduce the \"Feedforward Network\" behavior in slide 28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create input monitor\n",
    "mon_input  = SpikeMonitor(spikegen, name='mon_input')\n",
    "# create exc monitor\n",
    "mon_output = SpikeMonitor(exc, name='mon_output')\n",
    "\n",
    "# tune synaptic parameters\n",
    "syn_conf = {# nmda\n",
    "             \"I_tau_syn_exc\": 2.5 * pA,\n",
    "             \"I_g_syn_exc\": 0.3 * pA,\n",
    "    \n",
    "             # ampa, default\n",
    "             \"I_tau_syn_exc2\": 50 * pA,\n",
    "             \"I_g_syn_exc2\": 50 * pA}\n",
    "\n",
    "chip.set_param(syn_conf, 'Core_1')\n",
    "\n",
    "network.add([spikegen, exc, inh, syn_inp, syn_ee, syn_ei, syn_ie, mon_input, mon_output])\n",
    "\n",
    "# Simulation\n",
    "duration = 10 * second\n",
    "network.run(duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observe the behaviors of WTA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the output firing rates of the excitatory neurons in this feedforward network, and compare them with those of a WTA network later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_output = mon_output.count/ duration / Hz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can make a raster plot to visulize the spikes over time which shows the spike timings of each neuron. Also, we can put the mean firing rates of the neurons on the side to directly observe the population code in space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the raster plot and mean firing rates of spike generators\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, gridspec_kw={'width_ratios': [3, 1]}, figsize=(10,6), sharey=True)\n",
    "fig.text(0.45, 0.97, \"Input Stimulus\", ha=\"center\", va=\"bottom\", size=\"large\",color=\"k\")\n",
    "fig.tight_layout()\n",
    "\n",
    "ax1.plot(mon_input.t/ms, mon_input.i, '.k')\n",
    "ax1.set(xlabel='Time (ms)', ylabel='Neuron address')\n",
    "ax2.plot(mon_input.count/ duration / Hz, np.arange(num_exc), '-k')\n",
    "ax2.set(xlabel='Mean firing rate (Hz)')\n",
    "\n",
    "# plot the raster plot and mean firing rates of excitatory neurons in the feedforward network\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, gridspec_kw={'width_ratios': [3, 1]}, figsize=(10,6), sharey=True)\n",
    "fig.text(0.45, 0.97, \"Feedforward Network\", ha=\"center\", va=\"bottom\", size=\"large\",color=\"g\")\n",
    "fig.tight_layout()\n",
    "\n",
    "ax1.plot(mon_output.t/ms, mon_output.i, '.g')\n",
    "ax1.set(xlabel='Time (ms)', ylabel='Neuron address')\n",
    "ax2.plot(mon_output.count/ duration / Hz, np.arange(num_exc), '-g')\n",
    "ax2.set(xlabel='Mean firing rate (Hz)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks familiar right? Check slide 28! \n",
    "\n",
    "And now we turn on the WTA connections, i.e., syn_ee, syn_ei, syn_ie. Then if you properly tune the network parameters, you would see the higher peak gets stronger (the winner), and the lower peak is suppressed. You can tune the network to achieve a hard WTA, i.e. only one winner exists, or a soft WTA where the weaker bump are still active. \n",
    "\n",
    "Here, can you try to reproduce the \"Feedback Network\" result on the right-bottom of slide 28?\n",
    "\n",
    "Hint: you can play with the `gaussian_recurrent_excitation()` to try different recurrent excitation profile, and you can tune the synaptic paremeters to change the dynamics of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to start a new build to run multiple full simulations\n",
    "device.reinit()\n",
    "device.activate()\n",
    "# need to reset the defaultclock after activate\n",
    "defaultclock.dt = 20 * us\n",
    "\n",
    "# create a network\n",
    "network = Network()\n",
    "chip = DynapSE(network)\n",
    "\n",
    "# define the network parameters\n",
    "# number of exc neurons\n",
    "num_exc = 32\n",
    "# number of inh neurons\n",
    "num_inh = 8\n",
    "# probability of EI connections\n",
    "p_ei = 0.8\n",
    "# probability of IE connections\n",
    "p_ie = 0.8\n",
    "\n",
    "# Create stimulus\n",
    "rates_bump_1 = double2pop_code(value=0.5, inputSize=int(num_exc/2), sigma=3, amplitude=120)\n",
    "\n",
    "rates_bump_2 = double2pop_code(value=0.5, inputSize=int(num_exc/2), sigma=3, amplitude=80)\n",
    "\n",
    "rates = rates_bump_1 + rates_bump_2\n",
    "    \n",
    "# create spike generators for each exc neuron\n",
    "spikegen = PoissonGroup(num_exc, rates*Hz)\n",
    "\n",
    "\n",
    "######################## TODO ########################\n",
    "\n",
    "# create exc population\n",
    "\n",
    "# create inh population\n",
    "\n",
    "######################## TODO ########################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################### TODO ###############################\n",
    "\n",
    "# create synapses, turn on all WTA connections\n",
    "\n",
    "# syn_inp, spikegen to exc, one to one, NMDA\n",
    "\n",
    "# syn_ee, EE: play with gaussian_recurrent_excitation(), NMDA\n",
    "\n",
    "# syn_ei, EI: all to all with probability = 0.8, AMPA\n",
    "\n",
    "# syn_ie, IE: all to all with probability = 0.8, GABA_B\n",
    "\n",
    "############################### TODO ###############################\n",
    "\n",
    "syn_inp.weight = 300\n",
    "syn_ee.weight = 150\n",
    "syn_ei.weight = 300\n",
    "# Note: inhibitory weight should be negative! \n",
    "syn_ie.weight = -300\n",
    "\n",
    "\n",
    "######################## TODO ########################\n",
    "# tune the synaptic parameters to achieve the desired WTA behavior\n",
    "\n",
    "\n",
    "######################## TODO ########################\n",
    "\n",
    "\n",
    "\n",
    "# create input monitor\n",
    "mon_input  = SpikeMonitor(spikegen, name='mon_input')\n",
    "# create exc monitor\n",
    "mon_output = SpikeMonitor(exc, name='mon_output')\n",
    "# create inh monitor\n",
    "mon_inh = SpikeMonitor(inh, name='mon_inh')\n",
    "\n",
    "network.add([spikegen, exc, inh, syn_inp, syn_ee, syn_ei, syn_ie, mon_input, mon_output, mon_inh])\n",
    "\n",
    "# Simulation\n",
    "duration = 10 * second\n",
    "network.run(duration)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now plot the output firing rates of the excitatory neuron in the feedforward and the WTA network to see the function of the WTA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the raster plot and mean firing rates of excitatory neurons in the feedforward network and the WTA network to compare the difference.\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, gridspec_kw={'width_ratios': [3, 1]}, figsize=(10,6), sharey=True)\n",
    "fig.text(0.45, 0.97, \"WTA Network\", ha=\"center\", va=\"bottom\", size=\"large\",color=\"b\")\n",
    "fig.tight_layout()\n",
    "\n",
    "ax1.plot(mon_output.t/ms, mon_output.i, '.b')\n",
    "ax1.set(xlabel='Time (ms)', ylabel='Neuron address')\n",
    "\n",
    "ax2.plot(mon_output.count/ duration / Hz, np.arange(num_exc), '-b', label='WTA')\n",
    "ax2.plot(ff_output, np.arange(num_exc), '-g', label='FF')\n",
    "ax2.legend(loc=\"upper right\")\n",
    "ax2.set(xlabel='Mean firing rate (Hz)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you see a difference between the feedforward network and the WTA? \n",
    "\n",
    "Let's now plot the activity of the inhibitory neurons as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the raster plot and mean firing rates of inhibitory neurons.\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, gridspec_kw={'width_ratios': [3, 1]}, figsize=(10,6), sharey=True)\n",
    "fig.text(0.45, 0.97, \"Inhibitory neurons\", ha=\"center\", va=\"bottom\", size=\"large\",color='orange')\n",
    "fig.tight_layout()\n",
    "\n",
    "ax1.plot(mon_inh.t/ms, mon_inh.i, '.', color='orange')\n",
    "ax1.set(xlabel='Time (ms)', ylabel='Neuron address')\n",
    "\n",
    "ax2.plot(mon_inh.count/ duration / Hz, np.arange(num_inh), '-', color='orange')\n",
    "ax2.set(xlabel='Mean firing rate (Hz)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of firing rates in the inhibitory population are relatively uniform, right? Remember the connections between the excitatory and inhibitory populations? All the excitatory neurons activate the inhibitory neurons, and the inhibitory ones apply global inhibition to the excitatory ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, can you describe the different behaviors of the feedforward and WTA network and explain why? Please explain the dynamics of the WTA network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## TODO ###########################\n",
    "# Explain the dynamics/behaviors of WTA.\n",
    "\n",
    "\n",
    "############################## TODO ###########################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
